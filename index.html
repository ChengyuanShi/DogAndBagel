<!DOCTYPE html><html lang="en"><head>
    <script src="p5.js"></script>
    <script src="p5.sound.min.js"></script>
    <link rel="stylesheet" type="text/css" href="style.css">
    <meta charset="utf-8">
    <link rel="stylesheet" href="index.css" type="text/css">
  </head>
  <body>
    <h1>How Does Algorithmic Bias Affect People's Lives</h1>
    <h2>Abstract</h2>
    <h3>Throughout the course of history, human judgment is based on historical experience. However, it is not easy to avoid being influenced by personal emotions and power to lead to errors in judgment and unfairness. With the development of science and technology, significant breakthroughs have been made in the field of computers. The advent of artificial intelligence can help people solve many problems and make many judgments. Artificial intelligence, to a certain extent, excludes the influence of human emotions and then makes objective judgments. However, the truth is that while a handful of intelligent systems can do unbiased, most artificial intelligence still has algorithmic biases. Algorithmic bias is not new. Experts, for a long time, have tried to avoid the negative effects of algorithmic bias. This article discusses the challenges faced by artificial intelligence and explores algorithmic bias in depth. In addition to finding the cause of the algorithmic bias, it is important to understand the type of algorithmic bias, its impact, and how to avoid the algorithmic bias. The types of biases fall into four categories, such as model bias, the bias in interactions, emergent bias, and similarity bias. It is worth noting that the bias of the algorithmic is intertwined with racial disparity and gender differences. People's biases show up in the programming of computing. The conclusion was that humans were trying to use AI to make judgments and avoid bias, but it didn't occur to them that humans programmed AI. We add biases to computers, consciously, or unconsciously. Algorithmic bias cannot be completely avoided, only the probability of bias can be reduced as much as possible. It may be difficult for humans to design objective systems, but computers tend to be less biased than human judgments. Besides, artificial intelligence cannot be controlled by powerful people, or its existence would be meaningless.
    </h3>
    <h2>Introduction</h2>
    <h3>The idea of artificial intelligence may date back to the 17th century and reached its climax in the 21st century. At present, it can be said that the development of AI is getting faster and faster due to the maturity of Internet technology, the completion of big data, cloud computing, and other technologies. Just last year, Microsoft teamed up with OpenAI to develop a language-based artificial intelligence. According to Castelluccio (n.d.), "the GPT-3 is an autoregressive language model that's the most powerful natural language generation (NLG) model ever built. GPT-3 can write news stories and business memos. It can research and summarize case histories for lawyers, write fiction and poetry, and translate in several languages." In the process of improvement, AI exposed the existing deficiencies. A typical deficiency is called algorithmic bias. Nevertheless, scientists are working hard to contribute to AI's future development to face every challenge.</h3>
    <h2>Challenges Faced By Artificial Intelligence</h2>
    <h3>AI faces challenges in clinical medical practice. Few people outside of China know about Traditional Chinese Medicine(TCM); in TCM, the treatment process is divided into four steps--observation, auscultation & olfaction, inquiry, and pulse feeling & palpation. Doctors need to propose solutions based on patients' conditions, but the AI didn't follow the doctor's steps. The "Doctor AI" approach is to sift through the big data by first importing many patients' cases. If AI does not consider the personal conditions of specific patients when writing the program, the solution is biased. According to Kelly (2019), "AI algorithms have the potential to suffer from a host of shortcomings, including inapplicability outside of the training domain, bias and brittleness (tendency to be easily fooled)." It is easy to overlook the fact that unstable patient data obtained through AI can lead to inaccurate clinical and operational practices over time. Besides, the patient's situation can not be a comprehensive summary of all patients.
    </h3>
  <h3>AI faces legal challenges. The appearance of artificial intelligence is to facilitate people's life.  However, what is alarming is that AI tends to have a high degree of autonomy and be constantly detached from human control. The premise of positioning artificial intelligence's legal status is to determine whether artificial intelligence is a person or an object. If artificial intelligence is judged to be human, then it will confer legal rights. If artificial intelligence is classified as an object, then it has no legal rights. Here's a case where we can think about a self-driving car responsible after it hits a person? If it is entitled to liability, how will it pay compensation? If the car owner pays accident compensation, then it can be considered that a self-driving car has no legal rights and obligations; it is an object.</h3>
  <h3>AI faces challenges in the art field. With the development of high technology, especially after artificial intelligence, many arts are facing severe difficulties. The traditional way of painting is through the brush and paper; now, with the development of artificial intelligence, robots can also draw. Some people may question whether AI's work is art. In fact, in 2016, Google held an auction in San Francisco that featured 29 oil paintings by AI. In the end, six oil paintings were purchased. Artificial intelligence can be seen as playing the same role as painting tools. It cannot completely replace artists. Only work with soul and thoughts is called art. This kind of challenge is positive and can promote the creation of the artist.</h3>
  <h2>Type of Algorithmic Bias</h2>
  <h3>Computers have biases in the learning process, which means they have an unfair bias towards something. According to Sun (2020), “we argue that algorithmic bias evolves with human interaction in an iterative manner, which may have a long-term effect on algorithm performance and humans’ discovery and learning. ” In other words, algorithmic bias and human bias affect each other. The algorithmic bias can lead to the amplification of the human bias. Under the illusion that the software has no bias, people tend to trust the judgments of AI, ignoring that these judgments already reflect their own bias. Therefore, humans will undoubtedly accept the AI's decisions and create more biased data to further "enhance" themselves. Here are three types of  algorithmic bias that occur when a computer is running.</h3>
  <h3>1.Model Bias</h3>
  <h3>The chosen model best represents the majority of the population, not necessarily the particular individual. As noted above, model bias may occur in clinical practice. We think of patients as models, and AI builds healthcare systems by adding different models. The model is a variable, so there may be a bias in operation. Thiem (2020) plans to conduct experiments using Qualitative Comparative Analysis (QCA) to obtain valid data. However, the data acquisition quality of QCA is not high, and the application of related theories is not intelligent enough. Therefore, when the collected models are not representative of the whole, model bias can occur.
  </h3>
  <h3>2.Bias in interactions</h3>
  <h3>Some systems learn by looking at a broad set of examples, while others learn by interacting. The AI analyzes the user's personal preferences and habits through the interaction with the person. During the interaction process, the user will be influenced, and the bias will be formed- this is called the interactive bias. Bias is based on the users who drive the interaction. According to Hammond (2016), "A clear example of this bias is Microsoft's Tay, a Twitter-based chatbot designed to learn from its interactions with users. Unfortunately, Tay was influenced by a user community that taught Tay to be racist and misogynistic. In essence, the community repeatedly tweeted offensive statements at Tay, and the system used those statements as grist for later responses." In a word, user bias leads to algorithmic bias.  It is not difficult to find that intelligent robots are affected by the environment, which can be imagined as impacting individual human thinking. The individual's biases reflect the group's biases because the group influences the individual.
  </h3>
  <h3>3.Similarity bias</h3>
  <h3>Have you ever searched an image into an engine and found something else? Despite the similarities between the two, it's not the result you want. It  often happens when you search for blurry images.Try typing 'Chihuahua,' and you might see a picture of a "muffin." When you search the photos of "puppy," you might find "bagel."  However, a similar bias between the two examples did not have a negative effect. But when people are involved, it can be considered racist.  The Google Photos app sorts images by identifying objects in them. But when it comes to identifying people, there is a particular racial bias. Rekognition, a commercial face analysis system at Amazon, was also prone to gender and racial bias.</h3>
  <h2>Measures</h2>
  <h3>Once we understand the causes and types of bias, we can come up with solutions to reduce algorithmic bias. First, acknowledge the limitations of Artificial intelligence. Then, deep learning algorithms are not racist, they are human-influenced, and they will compensate for any biases that we may have consciously or unconsciously. According to Sun (2020), “researchers must carefully check the impact of algorithms on specific groups of people (such as defined by gender and race) before deploying algorithms.”  In order to reduce the occurrence of algorithmic bias, people are required to develop continuous monitoring, feedback, and updates. At the same time, to ensure that patients benefit from AI technology, it is essential to maintain a focus on clinical applicability and patient outcomes, improve the interpretability of algorithms, and better understand human-computer interaction.</h3>
  <h2>Conclusion</h2>
  <h3>Artificial intelligence technology can bring unexpected consequences, both positive and negative, to the future of mankind. We can't predict that at this stage. Future outcomes will depend on how we treat AI today. Human-computer interaction is the future of technology and the key to security. For most people, AI is expected to contribute to both the medical field and the art field. The original intention of AI creation will never change. It is dedicated to making the human lifestyle more wonderful.</h3>
  <h2>Bibliography</h2>
  <h3>Castelluccio, Michael. (n.d.). A Written Test For Artificial General Intelligence. Strategic Finance., 53–54.</h3>
  <h3>Hammond, Kristian. “5 Unexpected Sources of Bias in Artificial Intelligence.” TechCrunch. TechCrunch, December 10, 2016. https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligenc/. </h3>
  <h3>Kelly, Christopher J., Alan Karthikesalingam, Mustafa Suleyman, Greg Corrado, and Dominic King. 2019. “Key Challenges for Delivering Clinical Impact with Artificial Intelligence.” BMC Medicine 17 (1): N.PAG. doi:10.1186/s12916-019-1426-2
  </h3>
  <h3>Sîrbu, Alina, Dino Pedreschi, Fosca Giannotti, and János Kertész. 2019. “Algorithmic Bias Amplifies Opinion Fragmentation and Polarization: A Bounded Confidence Model.” PLoS ONE 14 (3): 1–20. doi:10.1371/journal.pone.0213246
  </h3>
  <h3>Sun, Wenlong, Olfa Nasraoui, and Patrick Shafto. 2020. “Evolution and Impact of Bias in Human and Machine Learning Algorithm Interaction.” PLoS ONE 15 (8): 1–39. doi:10.1371/journal.pone.0235502
  </h3>
  <h3>Thiem, Alrik, Lusine Mkrtchyan, Tim Haesebrouck, and David Sanchez. 2020. “Algorithmic Bias in Social Research: A Meta-Analysis.” PLoS ONE 15 (6): 1–16. doi:10.1371/journal.pone.0233625.
  </h3>



    <script src="sketch.js"></script>
      <script src="player.js"></script>
        <script src="dog1.js"></script>
        <script src="dog2.js"></script>
        <script src="dog3.js"></script>
        <script src="dog4.js"></script>
        <script src="bagel1.js"></script>
        <script src="bagel2.js"></script>
        <script src="bagel3.js"></script>
        <script src="bagel8.js"></script>


</body>
</html>
